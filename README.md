# ğŸ¬ tol_vido â€“ YouTube to Clean Text (LLM Powered)

[![Build](https://github.com/TamerOnLine/pro_venv/actions/workflows/test-pro_venv.yml/badge.svg)](https://github.com/TamerOnLine/pro_venv/actions)
[![License](https://img.shields.io/github/license/TamerOnLine/pro_venv?style=flat-square)](LICENSE)

`tol_vido` is a powerful, local-first Python tool that transcribes YouTube videos into well-formatted German paragraphs using Large Language Models (LLMs) like **Mistral** via `.gguf`. It's fast, customizable, and runs entirely on your machine.

---

## ğŸš€ Features

- âœ… Download and convert YouTube audio with `yt-dlp`
- âœ… Segment and transcribe speech with `SpeechRecognition` (Google)
- âœ… Format the raw text using a local LLM (e.g. Mistral via `llama-cpp-python`)
- âœ… Full local processing â€” **no cloud required**
- âœ… Modular and extensible codebase
- âœ… Auto-setup: project config, `venv`, VS Code files, and more

---

## ğŸ§± Project Structure

```bash
tol_vido/
â”œâ”€â”€ 01_pro_venv.py          # Setup: venv, config, VS Code
â”œâ”€â”€ 02_start_llm_server.py  # Run local LLM server
â”œâ”€â”€ 03_main.py              # Entry point runner
â”œâ”€â”€ app.py                  # Main processing logic
â”œâ”€â”€ extract_text_from_video.py  # Transcribe audio from video
â”œâ”€â”€ format_text.py          # Format using local LLM
â”œâ”€â”€ output.txt              # Raw transcription result
â”œâ”€â”€ formatted_output.txt    # Final cleaned-up version
â”œâ”€â”€ setup-config.json       # Project metadata
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ env-info.txt            # Python & installed packages
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ download_model.py   # GGUF model downloader
â””â”€â”€ .github/workflows/      # GitHub Actions
```

---

## â–¶ï¸ Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/YourUsername/tol_vido.git
cd tol_vido
```

### 2. Run the setup script

```bash
python 01_pro_venv.py
```

This will:
- Create a virtual environment
- Install dependencies
- Generate `main.py`, `app.py`, `.vscode/` settings

### 3. Start the LLM server
### âš ï¸ Important: Pre-Run Setup

Before running the main script, make sure the following steps are completed:

#### ğŸ“ 1. Download and place FFmpeg binaries
This project requires FFmpeg tools for audio conversion.

- Download from: [https://www.gyan.dev/ffmpeg/builds/](https://www.gyan.dev/ffmpeg/builds/)
- Extract and copy the following files into a folder named `bin/` in the project root:

```bash
bin/
â”œâ”€â”€ ffmpeg.exe
â”œâ”€â”€ ffprobe.exe
â”œâ”€â”€ ffplay.exe      # (optional)
```

> You **do not need** to add FFmpeg to your system PATH. The project uses them directly from `./bin/`.

---

#### ğŸ“„ 2. Create `.env` file

In the project root, create a file named `.env` with the following content:

```env
# Required for downloading and running the model
MODEL_NAME=mistral-7b-instruct-v0.1.Q4_K_M.gguf

# Local path to the GGUF model file (adjust this path to match your setup)
MODEL=r:/tol_vido/models/mistral-7b-instruct-v0.1.Q4_K_M.gguf

# LLM Server runtime parameters
N_CTX=4096
N_THREADS=8
N_GPU_LAYERS=35
VERBOSE=true
```

These values are used by:
- `tools/download_model.py` â€“ to fetch the model from Hugging Face
- `02_start_llm_server.py` â€“ to launch the local LLM inference server


```bash
python 02_start_llm_server.py
```

> Make sure the `.gguf` model exists in the `models/` folder. You can use `tools/download_model.py` to fetch it from Hugging Face.

### 4. Run the full pipeline

```bash
python 03_main.py
```

Youâ€™ll be prompted for a YouTube URL. After processing, the result will be saved in:

- `output.txt`: raw transcription  
- `formatted_output.txt`: structured, punctuated paragraphs

---

## ğŸ“¦ Requirements
---

## ğŸŒ Model Setup (GGUF)
### 2. Download the model

```bash
python tools/download_model.py
```

Model will be downloaded from:
> [TheBloke/Mistral-7B-Instruct-v0.1-GGUF](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF)

---

## ğŸ’¡ Notes

- All audio processing and formatting are local.
- Transcription uses `Google Speech Recognition` â€” no API key required.
- Formatting uses a **local** LLM server (default: `localhost:11434`).
- Works offline once the model is downloaded.

---

## ğŸ›  VS Code Support

The setup script automatically generates:

- `.vscode/settings.json` â†’ sets interpreter path
- `.vscode/launch.json` â†’ debugger config
- `project.code-workspace` â†’ pre-configured workspace

---

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).  
You are free to use, modify, and distribute it with attribution.  
Feel free to explore and build upon it!

---

## ğŸ™Œ Acknowledgements

This project would not have been possible without the following open-source tools and libraries. Sincere thanks to their developers and contributors:

- [Mistral 7B](https://mistral.ai) â€“ for providing the foundational language model.
- [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) â€“ for efficient local inference of LLMs.
- [yt-dlp](https://github.com/yt-dlp/yt-dlp) â€“ for reliable YouTube media extraction.
- [tiktoken](https://github.com/openai/tiktoken) â€“ for fast and accurate tokenization.

---

## ğŸ‘¨â€ğŸ’» About the Author

ğŸ¯ **Tamer OnLine â€“ Developer & Architect**  
A dedicated software engineer and educator with a focus on building multilingual, modular, and open-source applications using Python, Flask, and PostgreSQL.

ğŸ”¹ Founder of **Flask University** â€“ an initiative to create real-world, open-source Flask projects  
ğŸ”¹ Creator of [@TamerOnPi](https://www.youtube.com/@mystrotamer) â€“ a YouTube channel sharing tech, tutorials, and Pi Network insights  
ğŸ”¹ Passionate about helping developers learn by building, one milestone at a time

Connect or contribute:

[![GitHub](https://img.shields.io/badge/GitHub-TamerOnLine-181717?style=flat&logo=github)](https://github.com/TamerOnLine)  
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?style=flat&logo=linkedin)](https://www.linkedin.com/in/tameronline/)  
[![YouTube](https://img.shields.io/badge/YouTube-TamerOnPi-red?style=flat&logo=youtube)](https://www.youtube.com/@mystrotamer)
